\documentclass[a4paper,oneside,article,11pt]{memoir}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}

% This font looks so good.
\usepackage[sc]{mathpazo}

% Typesetting pseudo-code
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
% Code comments like [CLRS]
\renewcommand{\algorithmiccomment}[1]{\makebox[5cm][l]{$\triangleright$ \textit{#1}}}
\usepackage{framed,graphicx,xcolor}
\usepackage[font={small,it}]{caption}
\usepackage{listings}
\usepackage{units}

% Relative references
\usepackage{varioref}

\usepackage{hyperref}

\bibliographystyle{alpha}

\title{Advanced Data Structures \\ Project 3 - Theory project 5}
\author{Peter Gabrielsen 20114179 \\
Christoffer Hansen 20114637}
\newcounter{qcounter}
\begin{document}

\begin{titlingpage}
\clearpage

\maketitle
\thispagestyle{empty}

\begin{abstract}

\end{abstract}
\end{titlingpage}

\pagebreak

\tableofcontents

\pagebreak

\chapter{Introduction}
Introduction to the four exercises.

\chapter{Range minimum queries in two dimensions}
\label{chp:rmq2d}
\subsection{Problem description}
\textit{Let $A$ be a two dimensional array of size $n \times m$. Describe how to preprocess $A$ into a data structure that given a rectangular query range given by $(i_1,i_2,j_1,j_2)$ reports the minimum element in $A\left[ i1\dots i2\right]\left[j1\dots j2\right]$. State the space, preprocessing time, and query time of your data structure.}

\textit{Optional: What is the best space bound you can achieve with $\mathcal{O}(1)$ query time? What is the best query time you can achieve with $\mathcal{O}(nm)$ space?}

\subsection{Solution}
In the rest of this section we let $N = n\cdot m$.

There are several na√Øve solutions that comes to mind immediately. One such solution is to preprocess all possible ranges using dynamic programming giving $\mathcal{O}(N^2)$ preprocessing and space but with $\mathcal{O}(1)$ query time.
This solution is not reasonable for larger inputs and we must come up with a better solution. Another trivial thing we could do is to extend the idea of using Cartesian Trees\cite{vuillemin80,tarjan84} to solve 1D-RMQ on each row giving $\mathcal{O}(N)$ space and preprocessing time, and $\mathcal{O}(n)$ query time. Demaine~et~al~\cite{demaine09} show that the equivalent of the Cartesian tree in 1D does not exist in 2D and as such we cannot use Cartesian trees in 2D to solve this problem optimally.

\chapter{Nearest common ancestors under leaf insertions and deletions}
\label{chp:LCA}
\subsection{Problem description}
\textit{Describe a data structure to maintain a tree $T$ under the insertion and deletion of leafs (to insert a new leaf we are given a pointer to the parent node), while supporting nearest common ancestor queries of two arbitrary nodes in $T$. State the update and query time of your data structure.}

\textit{What are the best update and query bounds you can achieve?}

\subsection{Solution}
Might not be magic!

\chapter{In-place merging}
\label{chp:inplace}
\subsection{Problem description}
\textit{Describe an algorithm that given an array containing $m+n$ elements $x_1x_2\dots x_m y_1y_2\dots y_n$, where $x_1\leq x_2\leq \dots \leq x_m$ and $y_1\leq y_2\leq \dots \leq y_n$, inplace merges the two sorted sequences. State the running time of your algorithm.}

\textit{What is the best running time you can achieve?}

\subsection{Introduction}
Merging is the process of combining two pre-sorted lists to create a single sorted list. The natural way to merge two lists is to repeatedly compare the smallest elements from both lists and then output the smallest of the two. This is repeated until both lists are exhausted. This process requires $m+n-1$ comparisons and $m+n$ data moves. A merge is called stable if it preserves the order of the elements in the respective lists.

In this exercise we will look at merging two sorted lists in-place. A merge algorithm is said to be in-place if it uses no more than $\mathcal{O}(1)$ extra memory.

A solution to the problem of in-place merging two pre-sorted lists will be presented in the next section. This solution is not stable but is shown to be optimal up to the values of constants of proportionality in the space-time bounds. The solution was first presented by Kronrod in 1969 \cite{Kronrod}

\subsection{Kronrod}
Initially we chop up the two pre-sorted lists into blocks of size $k$, i.e. $k$ is the number of elements in each block. We set $k =\sqrt{m+n}$. The last element in each block is selected. We call this element the mark of each block. The blocks are then rearranged in sorted order according to the mark of each block into a list $L$ of length $m+n$. We can now conclude that each element is at most $k$ positions away from their final position in the merged array.

We now use the last two blocks in $L$ as a temporary output location for our merge operation. This means that the last two blocks become unsorted. When the temporary buffer becomes full, i.e. we have merged two blocks fully, we swap the two merged blocks that reside in the temporary buffer with the old unmerged blocks such that the merged blocks find their correct position in the list. We do this for all blocks until we reach the final two blocks. These blocks are the unsorted temporary buffer. The two buffers can be sorted using a selection sort in time $\mathcal{O}(2\cdot\left(\sqrt{m+n}\right)^2) = \mathcal{O}(m+n)$.

\subsection{Time complexity}
The initial rearrangement is a sorting of the marks. We have $\mathcal{O}(\sqrt{m+n})$ such marks and running an insertion sort on these element will run in $\mathcal{O}( (\sqrt{m+n})^2) = \mathcal{O}(m+n)$ time.

Merging two blocks consumes one comparison per element resulting in $m+n - 2\sqrt{m+n} = \mathcal{O}(m+n)$ comparisons.

Finally the last two blocks which makes up the temporary buffer are sorted using selection sort in time $\mathcal{O}(2\cdot\left(\sqrt{m+n}\right)^2) = \mathcal{O}(m+n)$.

In total we do $3\cdot\mathcal{O}(m+n) = \mathcal{O}(m+n)$ comparisons giving a linear time algorithm in the size of the input which is asymptotically optimal.

We can also argue about the number of data moves. Block rearrangement consumes 

\chapter{Prefix counting}
\label{chp:prefix}
\subsection{Problem description}
\textit{Let $A$ be an array of size $n$, where each $A\left[i\right]$ is either $0$ or $1$. Describe a data structure that supports updating an entry of $A$ to either $0$ or $1$, and the query $sum_2\left(i\right)$ that returns $\left(A\left[1\right]+A\left[2\right]+\dots+A\left[i\right]\right) \mod 2$, i.e. decides if the sum of the first $i$ entries of $A$ is odd or even.}

\textit{ is the best query time and update time you can achieve? A lower bound of $\Omega(\log n/\log\log n)$ is known for the operations on the RAM.}

\textit{Optional: Generalize the construction to return the sum $A[1]+A[2]+\dots+A[i]$, i.e. the number of entries equal one among the first $i$ entries.}

\subsection{Solution}
Build tree of height log n / loglog n and solve problem in constant time per node up to root.

\bibliography{references}

\end{document}


