\documentclass[a4paper,oneside,article,11pt]{memoir}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}

% This font looks so good.
\usepackage[sc]{mathpazo}

% Typesetting pseudo-code
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
% Code comments like [CLRS]
\renewcommand{\algorithmiccomment}[1]{\makebox[5cm][l]{$\triangleright$ \textit{#1}}}
\usepackage{framed,graphicx,xcolor}
\usepackage[font={small,it}]{caption}
\usepackage{listings}
\usepackage{units}
\usepackage{amsmath}

% Relative references
\usepackage{varioref}

\usepackage{hyperref}

\bibliographystyle{plain}

\title{Advanced Data Structures \\ Project 3 - Theory project 5}
\author{Christoffer Hansen 20114637}
\newcounter{qcounter}
\begin{document}

\begin{titlingpage}
\clearpage

\maketitle
\thispagestyle{empty}

\begin{abstract}

\end{abstract}
\end{titlingpage}

\pagebreak

\tableofcontents

\pagebreak

\chapter{Introduction}
Introduction to the four exercises.

\chapter{Range minimum queries in two dimensions}
\label{chp:rmq2d}
\subsection{Problem description}
\textit{Let $A$ be a two dimensional array of size $n \times m$. Describe how to preprocess $A$ into a data structure that given a rectangular query range given by $RMQ(i_1,i_2,j_1,j_2)$ reports the minimum element in $A\left[ i_1\dots i_2\right]\left[j_1\dots j_2\right]$. State the space, preprocessing time, and query time of your data structure.}

\subsection{Solution}
%TODO Insert references + figures.
The algorithm we propose is heavily inspired by the solution presented in ???. For simplicity we assume A to be a square with size $N = n^2$. The reader can verify that the solution we propose does not rely on this assumption and so it will also work for all input arrays with unequal side length.

We can trivially preprocess answers to all RMQs using dynamic programming in $\mathcal{O}(N^2)$ time and space such that a range minimum query can be answered in $\mathcal{O}(1)$ time. We will improve on the idea of preproccessing RMQs.

The key observation is that it is always possible to decompose a RMQ into four equal-sided overlapping rectangles whose side lengths are a power of two. Taking the position of where the overall minimum occurs is the answer to the query. This means it suffices to precompute $RMQ(i_1,i_1 + l_y,j_1,j_1 + l_x)$ for $i_1 \in Y \subseteq [0;n-1]$ $(j_1 \in X)$ and query lengths $l_y \in L_y = \{2^0, 2^1, \cdots \}$ ($l_x \in L_x$).

We denote by $g(\lvert Y \rvert, \lvert X \rvert, \lvert L_y \rvert, \lvert L_x \rvert) := \lvert Y \rvert \cdot \lvert X \rvert \cdot \log_2 \lvert L_y \rvert \cdot \log_2 \lvert L_x \rvert$ the space occupied by the resulting table for preprocessing using this idea. Using the idea naïvely yields an algorithm with $g(n,n,n,n) = N \log^2 n$ preprocessing time and space and $\mathcal{O}(1)$ query time.

In order to improve on this, we will cover the input array with grids of different size such that we can answer queries. Referring to figure ??? it is obvious that a query that crosses such a grid can be divided into at most nine sub-queries; four corner-queries, four side-queries and one full-block-query. We will precompute tables such that we can answer these sub-queries in $\mathcal{O}(1)$ time.

We start out by setting the grid size $s = \log_2 n$.

\subsection{Full-block-query}
We precompute a table $\forall x,y \in \{0,1,2, \cdots, \nicefrac{n}{s} \}$ and $\forall k,l \in \{0,1,2, \cdots, \log$ $\nicefrac{n}{s} \}$ with entries that can answer queries on the form $RMQ(ys,xs,(y+2^k)s,(x+2^l)s)$. The space and preprocess time is
\begin{align}
g(\nicefrac{n}{s}, \nicefrac{n}{s}, \nicefrac{n}{s}, \nicefrac{n}{s}) &\leq \nicefrac{n}{s} \cdot \nicefrac{n}{s} \cdot \log n \cdot \log n \\ &= \nicefrac{n}{\log n} \cdot \nicefrac{n}{\log n} \cdot \log n \cdot \log n \\ &= n^2 \\ &= N &= O(N)
\end{align}


\subsection{Side-queries}
It is obvious we cannot naïvely reuse the idea and precompute all RMQs for the side-queries as this would result in super-linear space and preprocessing time. To overcome this we block the grid into "super-blocks" of size $s' = s^2$. We will precompute tables that can answer a side-query by one table-lookup for the part of the query that spans over several super-blocks and at most two queries that answers side-queries which spans over several blocks but not over a super-block. This will makes us able to answer a query in the form $RMQ(y_1,x_1s,y_1+l_y,x_1s+l_x)$ for all $y_1 \in \{0, \cdots n-1 \}$, $x_1 \in \{0, \cdots, \nicefrac{n}{s} \}$, $l_y \in \{1, \cdots, s \}$ and $l_x \in \{s,2s, \cdots, \nicefrac{n}{s} \}$.

For precomputing a table for the super-block-queries we need space and time proportional to:
\begin{align}
g(n, \nicefrac{n}{s'}, s, \nicefrac{n}{s'}) &= n \cdot \nicefrac{n}{\log^2 n} \cdot \log \log n \cdot \log \nicefrac{n}{\log^2 n} \\ &\leq n^2 \cdot \nicefrac{\log \log n}{\log n} \\ &= \mathcal{O}(n^2) &= O(N)
\end{align}

For precomputing a table for the block-queries we need space and time proportional to:
\begin{align}
g(n, \nicefrac{n}{s}, s, \nicefrac{s'}{s}) &= n \cdot \nicefrac{n}{\log n} \cdot \log \log n \cdot \log \log n &= O(N)
\end{align}

\subsection{Corner-queries}
Corner-queries can be answered by a single table-lookup on the form \\ $RMQ(y_1s,x_1,s+l_y,x_1+l_x)$ for all $y_1 \in \{0,\cdots,\nicefrac{n}{s} \}$, $x_1 \in \{0, \cdots, n-1 \}$ and $l_x,l_y \in \{1, \cdots, s \}$ giving a total time and space consumption of
\begin{align}
g(\nicefrac{n}{s}, n, s, s) &= \nicefrac{n}{\log n} \cdot n \cdot \log \log n \cdot \log \log n &= O(N)
\end{align}

\subsection{Recursive partitioning}
Now, we perform the same preprocessing for grid-widths $s_2 = \log \log n$, $s_3 = \log \log \log n$, $\cdots$, $s_k = log^{[k]} n$. We will continue building look-tables for each level $l$ until $s_l = \mathcal{O}(1)$ which per definition of the iterated log function is at $l = \theta(\log^* n)$. If we were to naïvely answer queries we would have to visit each level until the first time $k$ the RMQ crosses the $k$-level grid. This would cost $\mathcal{O}(\log^* n)$ time. We overcome this by storing an additional structure of size $\mathcal{O}(n)$ that select the right grid in $\mathcal{O}(1)$ time given the query length.

\subsection{Microblocks}
What is left is to show how to handle queries that is fully contained within the smallest possible grid-cell. It is obvious that 2 blocks yields the same answer to all RMQs if their corresponding elements have the same relative order. Using this fact, we sort each block of $S = s^2_l$ to get the permutation of $[1,S]$. Now we precompute microblock queries only for different permutations. As we have micro-blocks of constant size we are able to sort in $\mathcal{O}(1)$ time each. There are $\nicefrac{n}{(\log^* n)^2}$ micro-blocks given a space and time consumption of $\mathcal{O}(N)$.

\subsection{Conclusion}
We have showed a solution that converges towards an algorithm with $\mathcal{O}(N \log^* N)$ space and preprocessing time and $\mathcal{O}(1)$ query time.

\chapter{Nearest common ancestors under leaf insertions and deletions}
\label{chp:LCA}
\subsection{Problem description}
\textit{Describe a data structure to maintain a tree $T$ under the insertion and deletion of leafs (to insert a new leaf we are given a pointer to the parent node), while supporting nearest common ancestor queries of two arbitrary nodes in $T$. State the update and query time of your data structure.}

\textit{What are the best update and query bounds you can achieve?}

\subsection{Solution}
Might not be magic!

\chapter{In-place merging}
%TODO Insert references.
\label{chp:inplace}
\subsection{Problem description}
\textit{Describe an algorithm that given an array containing $n+m$ elements $x_1x_2\dots x_ny_1y_2\dots y_m$, where $x_1\leq x_2\leq \dots \leq x_n$ and $y_1\leq y_2\leq \dots \leq y_m$, inplace merges the two sorted sequences. State the running time of your algorithm.}

\textit{What is the best running time you can achieve?}

\subsection{Solution}
We use the solution presented by Kronrod in ???. We divide the input array into blocks of size $k = \sqrt{m+n}$. In each block we select the last element and rearrange blocks in sorted order of the value of the selected location into a list $L$ of size $m+n$. This will make no value in $L$ be more than $k$ locations away from its final position.
Now we can use the last two blocks $L$ as a temporary merge-buffer by exchanging elements as we merge. Whenever the merge-buffer becomes full we can simply swap the merged blocks with the merge-buffer. Repeating this will make the last two blocks become unsorted. We sort the last two blocks using Selection sort.

\subsection{Conclusion}
Correctness follows directly from construction. The division of blocks and selection of the last element can be done in $\mathcal{O}(\sqrt{m+n})$. We rearrange blocks using Insertion sort in $\mathcal{O}((\sqrt{m+n})^2) = \mathcal{O}(m+n)$. Except for the last two blocks we merge all blocks using $\mathcal{O}(m+n)$ comparisons. Selection sort of the last two blocks is done in $\mathcal{O}((\sqrt{m+n})^2) = \mathcal{O}(m+n)$ time. This gives an optimal $\mathcal{O}(m+n)$ algorithm.

\chapter{Prefix counting}
%TODO Insert references.
\label{chp:prefix}
\subsection{Problem description}
\textit{Let $A$ be an array of size $n$, where each $A\left[i\right]$ is either $0$ or $1$. Describe a data structure that supports updating an entry of $A$ to either $0$ or $1$, and the query $sum_2\left(i\right)$ that returns $\left(A\left[1\right]+A\left[2\right]+\dots+A\left[i\right]\right) \mod 2$, i.e. decides if the sum of the first $i$ entries of $A$ is odd or even.}

\textit{ is the best query time and update time you can achieve? A lower bound of $\Omega(\log n/\log\log n)$ is known for the operations on the RAM.}

\subsection{Solution}
We precompute a lookup-table of size $2^{\log n} = n$ that can answer parity of $\log n$ bits in $\mathcal{O}(1)$ time. Given an input array we block each $\log n$ bits and store them in leaves of a tree with fanout $\log n$. This gives the a tree of height $\theta(\nicefrac{\log n}{\log \log n})$. In each of the internal nodes we store the parity of each of its $\log n$ children in a $\log n$-bit vector. We will now describe how to perform query and update operations.

\begin{itemize}
	\item{\textit{Query(i)} - We compute the parity of $A[i]$ using table lookups of the left siblings of the nodes on the path from the $i$'th leaf back to the root. This can be done in time proportional to the height of the tree as we are able to handle each node in O(1) time using the lookup table.}
	\item{\textit{Update(i,b)} - We update the value of the $i$'th leaf to $b$ and recursively propagate the parity from leaf to root using table lookups. }
\end{itemize}

\subsection{Conclusion}
Correctness follows directly from construction. Since both operations traverse the tree from leaf to root, and we are able to handle each node in $\mathcal{O}(1)$ using table lookups, we get a complexity of $\mathcal{O}(\nicefrac{\log n}{\log \log n})$.


\bibliography{references}

\end{document}


