\documentclass[a4paper,oneside,article,11pt]{memoir}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}

% This font looks so good.
\usepackage[sc]{mathpazo}

% Typesetting pseudo-code
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
% Code comments like [CLRS]
\renewcommand{\algorithmiccomment}[1]{\makebox[5cm][l]{$\triangleright$ \textit{#1}}}
\usepackage{framed,graphicx,xcolor}
\usepackage[font={small,it}]{caption}
\usepackage{listings}
\usepackage{units}
\usepackage{amsmath}

% Relative references
\usepackage{varioref}

\usepackage{hyperref}

\bibliographystyle{plain}

\title{Advanced Data Structures \\ Project 3 - Theory project 5}
\author{Christoffer Hansen 20114637}
\newcounter{qcounter}
\begin{document}

\begin{titlingpage}
\clearpage

\maketitle
\thispagestyle{empty}

\begin{abstract}
This project aims at presenting theoretical solutions for the problems of \textit{2D range minimum queries}, \textit{Nearest common ancestors under leaf insertion and deletion}, \textit{Inplace merging} and \textit{Prefix counting}. For the \textit{2D range minimum queries} problem we present a solution that converges towards $\mathcal{O}(N \log^* N)$ space and preprocessing time and $\mathcal{O}(1)$ query time. The solution we present for \textit{Nearest common ancestors under leaf insertion and deletion} is shown to be amortized $\mathcal{O}(\log n)$ for all operations by using Link/cut trees. We solve the \textit{Inplace merging} problem through a method original presented by Kronrod. This solution, we show to be an optimal $\mathcal{O}(m+n)$ algorithm. Finally we solve the \textit{Prefix counting} problem with a complexity of $\mathcal{O}(\nicefrac{\log n}{\log \log n})$ for the \texttt{update} and \textit{query} operations. This complexity matches the currently best known result.
\end{abstract}
\end{titlingpage}

\pagebreak

\tableofcontents

\pagebreak

\chapter{Range minimum queries in two dimensions}
\label{chp:rmq2d}
\subsection{Problem description}
\textit{Let $A$ be a two dimensional array of size $n \times m$. Describe how to preprocess $A$ into a data structure that given a rectangular query range given by $RMQ(i_1,i_2,j_1,j_2)$ reports the minimum element in $A\left[ i_1\dots i_2\right]\left[j_1\dots j_2\right]$. State the space, preprocessing time, and query time of your data structure.}

\subsection{Solution}
The algorithm we propose is inspired by a solution presented by Amir et al. in~\cite{AmirFL07}. For simplicity we assume A to be a square with size $N = n^2$. The reader can verify that the solution we propose does not rely on this assumption and so it will also work for all input arrays with unequal side length.

We can trivially preprocess answers to all RMQs using dynamic programming in $\mathcal{O}(N^2)$ time and space such that a range minimum query can be answered in $\mathcal{O}(1)$ time. We will improve on the idea of preproccessing RMQs.

The key observation is that it is always possible to decompose a RMQ into four equal-sided overlapping rectangles whose side lengths are a power of two. Taking the position of where the overall minimum occurs is the answer to the query. This means it suffices to precompute $RMQ(i_1,i_1 + l_y,j_1,j_1 + l_x)$ for $i_1 \in Y \subseteq [0;n-1]$ $(j_1 \in X)$ and query lengths $l_y \in L_y = \{2^0, 2^1, \cdots \}$ ($l_x \in L_x$).

We denote by $g(\lvert Y \rvert, \lvert X \rvert, \lvert L_y \rvert, \lvert L_x \rvert) := \lvert Y \rvert \cdot \lvert X \rvert \cdot \log_2 \lvert L_y \rvert \cdot \log_2 \lvert L_x \rvert$ the space occupied by the resulting table for preprocessing using this idea. Using the idea naïvely yields an algorithm with $g(n,n,n,n) = N \log^2 n$ preprocessing time and space and $\mathcal{O}(1)$ query time.

In order to improve on this, we will cover the input array with grids of different size such that we can answer queries. Referring to figure~\ref{fig:rmq_2d} it is obvious that a query which crosses such a grid can be divided into at most nine sub-queries; four corner-queries, four side-queries and one full-block-query. We will precompute tables such that we can answer these sub-queries in $\mathcal{O}(1)$ time.

\begin{figure}[H]
    \centering    
    \includegraphics[width=\textwidth]{../figures/rmq_q.png}
    \caption{2D RMQ on grid-width $\log_2 n$}
    \label{fig:rmq_2d}
\end{figure}

We start out by setting the grid size $s = \log_2 n$.

\subsection{Full-block-query}
We precompute a table $\forall x,y \in \{0,1,2, \cdots, \nicefrac{n}{s} \}$ and $\forall k,l \in \{0,1,2, \cdots, \log$ $\nicefrac{n}{s} \}$ with entries that can answer queries on the form $RMQ(ys,xs,(y+2^k)s,(x+2^l)s)$. The space and preprocess time is
\begin{align}
g(\nicefrac{n}{s}, \nicefrac{n}{s}, \nicefrac{n}{s}, \nicefrac{n}{s}) &\leq \nicefrac{n}{s} \cdot \nicefrac{n}{s} \cdot \log n \cdot \log n \\ &= \nicefrac{n}{\log n} \cdot \nicefrac{n}{\log n} \cdot \log n \cdot \log n \\ &= n^2 \\ &= N &= \mathcal{O}(N)
\end{align}


\subsection{Side-queries}
It is obvious we cannot naïvely reuse the idea and precompute all RMQs for the side-queries as this would result in super-linear space and preprocessing time. To overcome this we block the grid into "super-blocks" of size $s' = s^2$. We will precompute tables that can answer a side-query by one table-lookup for the part of the query that spans over several super-blocks and at most two queries that answers side-queries which spans over several blocks but not over a super-block. This will makes us able to answer a query on the form $RMQ(y_1,x_1s,y_1+l_y,x_1s+l_x)$ for all $y_1 \in \{0, \cdots n-1 \}$, $x_1 \in \{0, \cdots, \nicefrac{n}{s} \}$, $l_y \in \{1, \cdots, s \}$ and $l_x \in \{s,2s, \cdots, \nicefrac{n}{s} \}$.

For precomputing a table for the super-block-queries we need space and time proportional to:
\begin{align}
g(n, \nicefrac{n}{s'}, s, \nicefrac{n}{s'}) &= n \cdot \nicefrac{n}{\log^2 n} \cdot \log \log n \cdot \log \nicefrac{n}{\log^2 n} \\ &\leq n^2 \cdot \nicefrac{\log \log n}{\log n} \\ &= \mathcal{O}(n^2) &= \mathcal{O}(N)
\end{align}

For precomputing a table for the block-queries we need space and time proportional to:
\begin{align}
g(n, \nicefrac{n}{s}, s, \nicefrac{s'}{s}) &= n \cdot \nicefrac{n}{\log n} \cdot \log \log n \cdot \log \log n &= \mathcal{O}(N)
\end{align}

\subsection{Corner-queries}
Corner-queries can be answered by a single table-lookup on the form \\ $RMQ(y_1s,x_1,s+l_y,x_1+l_x)$ for all $y_1 \in \{0,\cdots,\nicefrac{n}{s} \}$, $x_1 \in \{0, \cdots, n-1 \}$ and $l_x,l_y \in \{1, \cdots, s \}$ giving a total time and space consumption of
\begin{align}
g(\nicefrac{n}{s}, n, s, s) &= \nicefrac{n}{\log n} \cdot n \cdot \log \log n \cdot \log \log n &= \mathcal{O}(N)
\end{align}

\subsection{Recursive partitioning}
Now, we perform the same preprocessing for grid-widths $s_2 = \log \log n$, $s_3 = \log \log \log n$, $\cdots$, $s_k = log^{[k]} n$. We will continue building look-tables for each level $l$ until $s_l = \mathcal{O}(1)$ which, per definition of the iterated log function, is at $l = \theta(\log^* n)$. If we were to naïvely answer queries we would have to visit each level until the first time $k$ the RMQ crosses the $k$-level grid. This would cost $\mathcal{O}(\log^* n)$ time. We overcome this by storing an additional structure of size $\mathcal{O}(n)$ that select the right grid in $\mathcal{O}(1)$ time given the query length.

\subsection{Microblocks}
What is left is to show how to handle queries that is fully contained within the smallest possible grid-cell. It is obvious that 2 blocks yields the same answer to all RMQs if their corresponding elements have the same relative order. Using this fact, we sort each block of $S = s^2_l$ to get the permutation of $[1,S]$. Now we precompute microblock queries only for different permutations. As we have micro-blocks of constant size we are able to sort in $\mathcal{O}(1)$ time each. There are $(\nicefrac{n}{\log^* n})^2$ micro-blocks giving a space and time consumption of $\mathcal{O}(N)$.

\subsection{Conclusion}
We have shown a solution that solves the range minimum query problem for two dimensions. The solution converges towards an algorithm with $\mathcal{O}(N \log^* N)$ space and preprocessing time and $\mathcal{O}(1)$ query time.

\chapter{Nearest common ancestors under leaf insertions and deletions}
\label{chp:LCA}
\subsection{Problem description}
\textit{Describe a data structure to maintain a tree $T$ under the insertion and deletion of leafs (to insert a new leaf we are given a pointer to the parent node), while supporting nearest common ancestor queries of two arbitrary nodes in $T$. State the update and query time of your data structure.}

\textit{What are the best update and query bounds you can achieve?}

\subsection{Solution}
We use Link/Cut trees invented by Sleator and Tarjan in 1983~\cite{Sleator1983}. Link/Cut trees divide each tree in the represented forest into vertex-disjoint path, where each path is represented by an auxiliary tree. The original paper makes use of \textit{biased binary trees}. We will instead use splay-trees as they simplify the data structure and yield the same asymptotic time bound. The nodes in the splay-trees are keyed by their depth in the corresponding represented tree.

\subsection{Structure}
We will take the \textit{represented tree} and split it into paths. Each path is represented internally by splay-trees where an in-order tree walk represent the path from the root to the last node on the path. We denote a \textit{preferred path} as the path taken when \textit{accessing} a node $v$. As a node $v$ can only have one \textit{preferred child} we simply remember the latest accessed child of a path going through $v$. Connected nodes not on the same preferred path are connected using a \textit{path-parent} pointer stored in the root of the splay-tree.

\subsection{Operations}
Link/Cut trees support the operations \texttt{FindRoot(v)}, \texttt{Cut(v)} and \texttt{Link(u,v)} in amortized $\mathcal{O}(\log n)$ time. All operations makes use of an auxiliary operation \texttt{Access(v)} that we will explain in detail since it is the key our solution for answering NCA-queries. When we \textit{access} a vertex $v$ we make root-to-v path preferred and splay $v$ to the root of the corresponding auxiliary tree. Now we remove $v$'s preferred child (if any) as it is no longer on the preferred path. We now walk up the represented tree to the root, breaking and resetting the preferred path where necessary. We do this by repeatedly splaying \textit{parent-path[v]} and switching its preferred child with $v$ until \textit{parent-path[v]} is \textit{null}.

\subsection{NCA Query}
We are ready to introduce the operation for answering NCA-queries. Given NCA(u,v) we first \texttt{Access(u)}. This makes a preferred root-to-u path. Now we invoke \texttt{Access(v)} followed by \texttt{splay(u)}. The answer of the query is \textit{parent-path[u]}.

\subsection{Correctness}
The invocation of \texttt{Access(u)} will build a preferred path from the root to $u$. The invocation of \texttt{Access(v)} will cross this path in the nearest common ancestor. This will make the splay-tree, which belongs to $u$, have a path-parent pointer to the nearest common ancestor after we invoke \texttt{splay(u)}. This follows directly from the construction of \texttt{Access(u)}.

\subsection{Complexity}
From~\cite{Sleator1985} we know the splay-tree have an amortized $\mathcal{O}(\log n)$ complexity for all operations. The operations \texttt{Cut(v)}, \texttt{Link(u,v)} are $\mathcal{O}(1)$ constant time operations plus the cost of \texttt{Access(v)}. The operations \texttt{FindRoot(v)} and \texttt{NCA(u,v)} has an imposed contribution of amortized $\mathcal{O}(\log n)$ from the splay-tree plus the cost of \texttt{Access(v)}. So it remains to bound \texttt{Access(v)} in order to find the overall complexity of the data structure.
As we do a constant number of operations each time we visit an unpreferred edge on any path, we want to bound this number. We analyse this using heavy-light decomposition~\cite{jefferickson2006}. The number of light unpreferred edges we can hit on any given path is at most $\log n$. For the heavy edges we amortize over all operations. Assume there are $m$ operations in total. After all operations have been performed there can at most be $n-1$ heavy preferred edges. While having this bound we must have that each time a heavy edge becomes preferred, another heavy edge must become unpreferred. This will only happen through an \texttt{Access(v)} operations, and so during this a light edge will become preferred. This is bounded by $\log n$, so the total cost over the $m$ operations is $\mathcal{O}(m\log n + n)$. Assume $m > n$. This is $\mathcal{O}(\log n)$ amortized per operation or a total of $\mathcal{O}(\log^2 n)$ total cost.

It is obvious we can achieve an amortized $\mathcal{O}(\log n)$ complexity under the assumption each preferred child change has cost $\mathcal{O}(1)$ amortized. This is shown to be the case in~\cite{jefferickson2006}.

Since our \texttt{NCA(u,v)} operation only makes use of \texttt{Access(v)} and \texttt{Splay(v)} we conclude the data structure to be amortized $\mathcal{O}(\log n)$ for all operations.


\chapter{In-place merging}
\label{chp:inplace}
\subsection{Problem description}
\textit{Describe an algorithm that given an array containing $n+m$ elements \\ $x_1x_2\dots x_ny_1y_2\dots y_m$, where $x_1\leq x_2\leq \dots \leq x_n$ and $y_1\leq y_2\leq \dots \leq y_m$, inplace merges the two sorted sequences. State the running time of your algorithm.}

\textit{What is the best running time you can achieve?}

\subsection{Solution}
We use the solution presented by Kronrod in 1969~\cite{Kronrod}. We divide the input array into blocks of size $k = \sqrt{m+n}$. In each block we select the last element and rearrange blocks in sorted order of the value of the selected location into a list $L$ of size $m+n$. This will make no value in $L$ be more than $k$ locations away from its final position.
Now we can use the last two blocks $L$ as a temporary merge-buffer by exchanging elements as we merge. Whenever the merge-buffer becomes full we can simply swap the merged blocks with the merge-buffer. Repeating this will make the last two blocks become unsorted. We sort the last two blocks using Selection sort.

\subsection{Conclusion}
Correctness follows directly from construction. The division of blocks and selection of the last element can be done in $\mathcal{O}(\sqrt{m+n})$. We rearrange blocks using Insertion sort in $\mathcal{O}((\sqrt{m+n})^2) = \mathcal{O}(m+n)$. Except for the last two blocks we merge all blocks using $\mathcal{O}(m+n)$ comparisons. Selection sort of the last two blocks is done in $\mathcal{O}((\sqrt{m+n})^2) = \mathcal{O}(m+n)$ time. This gives an optimal $\mathcal{O}(m+n)$ algorithm.

\chapter{Prefix counting}
\label{chp:prefix}
\subsection{Problem description}
\textit{Let $A$ be an array of size $n$, where each $A\left[i\right]$ is either $0$ or $1$. Describe a data structure that supports updating an entry of $A$ to either $0$ or $1$, and the query $sum_2\left(i\right)$ that returns $\left(A\left[1\right]+A\left[2\right]+\dots+A\left[i\right]\right) \mod 2$, i.e. decides if the sum of the first $i$ entries of $A$ is odd or even.}

\textit{ is the best query time and update time you can achieve? A lower bound of $\Omega(\log n/\log\log n)$ is known for the operations on the RAM.}

\subsection{Solution}
We precompute a lookup-table of size $2^{\log n} = n$ that can answer parity of $\log n$ bits in $\mathcal{O}(1)$ time. Given an input array we block each $\log n$ bits and store them in leaves of a tree with fanout $\log n$. This gives the a tree of height $\Theta(\nicefrac{\log n}{\log \log n})$. In each of the internal nodes we store the parity of each of its $\log n$ children in a $\log n$-bit vector. We will now describe how to perform query and update operations.

\begin{itemize}
	\item{\textit{Query(i)} - We compute the parity of $A[i]$ using table lookups of the left siblings of the nodes on the path from the $i$'th leaf back to the root. This can be done in time proportional to the height of the tree as we are able to handle each node in O(1) time using the lookup table.}
	\item{\textit{Update(i,b)} - We update the value of the $i$'th leaf to $b$ and recursively propagate the parity from leaf to root using table lookups. }
\end{itemize}

\subsection{Conclusion}
Correctness follows directly from construction. Since both operations traverse the tree from leaf to root, and we are able to handle each node in $\mathcal{O}(1)$ using table lookups, we get a complexity of $\mathcal{O}(\nicefrac{\log n}{\log \log n})$.


\bibliography{references}

\end{document}


